---
title: "Proyecto"
format: pdf
editor: visual
---

## Primera Entrega Trabajo Semestral

```{r,results='hide', warning=FALSE,message=FALSE}
library(tidyverse)
library(caret)
library(ggplot2)
library(e1071)
library(DataExplorer)
library(pROC)
library(caTools)
library(MASS)
library(class)
library(rpart)
library(readr)
library(factoextra)
```

```{r}
df_train<-read.csv("C:/Users/Asus/OneDrive/Escritorio/Analisis de negocios/test.csv")
df_test<-read.csv("C:/Users/Asus/OneDrive/Escritorio/Analisis de negocios/train.csv")
```

```{r}
set.seed(1)
```

### EDA

```{r}
glimpse(df_train)
```

```{r}
df_train$Gender<-as.factor(df_train$Gender)
df_test$Gender<-as.factor(df_test$Gender)

df_train$Customer.Type<-as.factor(df_train$Customer.Type)
df_test$Customer.Type<-as.factor(df_test$Customer.Type)

df_train$Type.of.Travel<-as.factor(df_train$Type.of.Travel)
df_test$Type.of.Travel<-as.factor(df_test$Type.of.Travel)

df_train$Class<-as.factor(df_train$Class)
df_test$Class<-as.factor(df_test$Class)

df_train$satisfaction<-as.factor(df_train$satisfaction)
df_test$satisfaction<-as.factor(df_test$satisfaction)
```

```{r}
glimpse(df_train)
```

Podemos observar que el ID y la columna X no nos otorgan información relevante para el análisis, por lo tanto, las eliminamos:

```{r,echo=FALSE}
df_train<-df_train %>% dplyr:: select (-id)
df_test<-df_test %>% dplyr:: select (-id)

df_train<-df_train %>% dplyr:: select (-X)
df_test<-df_test %>% dplyr:: select (-X)

```

```{r,fig.width=7,fig.height=3}
plot_intro(df_train)
```

Ahora se completan las observaciones que faltan. Esto es muy importante para poder trabajar correctamente los datos.

```{r}
# Valores perdidos
df_train <- df_train[complete.cases(df_train),]
df_test <- df_test[complete.cases(df_test),]
```

```{r}
plot_intro(df_train)
plot_intro(df_test)
```

```{r}
plot_correlation(df_train)
```

Por otro lado, la tabla de correlación es clave para la preparación del modelo, ya que cuantifica que tanto se relacionan las distintas variables con la variable dependiente satisfaction).

```{r}
variables_numericas<-df_train[,sapply(df_train,is.numeric)] #selecciona las columnas numericas
matriz_correlacion <- cor(variables_numericas, as.numeric(df_train$satisfaction))
matriz_correlacion
```

Ahora, para ver si existen outliers, dada la naturaleza de las variables, solo se estudiaran las asociadas a los tiempos de delay:

```{r}
boxplot(df_train$Departure.Delay.in.Minutes,ylab="Tiempo de delay en la salida en minutos")
boxplot(df_train$Arrival.Delay.in.Minutes,ylab="Tiempo de delay en la llegada en minutos")
```

De esto se infiere que, si bien se observan outliers, dentro del contexto del problema estarían justificados dada la naturaleza del servicio y de los vuelos, además, al analizar dichos datos con valores muy grandes, podemos notar que son coincidentes un largo delay en la salida del vuelo con un largo tiempo de atraso en la llegada, confirmando el supuesto de que simplemente el vuelo se atrasó muchas horas.

```{r}
ggplot(df_train, aes(x=Class,fill=satisfaction))+
geom_bar(position = 'fill')+theme_bw()+
scale_x_discrete(label=function(x) str_wrap(x,width=10))

ggplot(df_train, aes(x=Customer.Type,fill=satisfaction))+
geom_bar(position = 'fill')+theme_bw()+
scale_x_discrete(label=function(x) str_wrap(x,width=10))

ggplot(df_train, aes(x=Type.of.Travel,fill=satisfaction))+
geom_bar(position = 'fill')+theme_bw()+
scale_x_discrete(label=function(x) str_wrap(x,width=10))

ggplot(df_train, aes(x=Gender,fill=satisfaction))+
geom_bar(position = 'fill')+theme_bw()+
scale_x_discrete(label=function(x) str_wrap(x,width=10))
```

\*\*Gender-\>asociarlo a la tabla de correlacion (no importa:))

Dada la naturaleza de la variable que queremos obtener, utilizaremos las siguientes regresiones para crear el modelo buscado

# Métodos supervisados

## 1. Modelo Regresión Logística

```{r}
attach(df_train)
```

```{r}
glm.fit<-glm(satisfaction ~ .-Gender, family=binomial, data=df_train)
summary(glm.fit)
```

Notamos que, sin considerar el género, todas las variables son significativas para el modelo, sin embargo, la locación de la puerta y el servicio de comida y bebidas serían menos importantes.

```{r}
pred_logistic<-predict(glm.fit,df_test,type="response") #matriz de predicciones
y_pred = rep("neutral or dissatisfied", length(pred_logistic))
y_pred[pred_logistic > 0.50678] = "satisfied"
y_pred<-as.factor(y_pred)
confusionMatrix(y_pred, df_test$satisfaction, positive = "satisfied")
```

```{r}
roc_obj<-roc(df_test$satisfaction,pred_logistic)
plot(roc_obj)
auc(roc_obj) #para el area bajo la curva
```

De este gráfico podemos inferir que el modelo entregaría buenos resultados al tener una gran área bajo la curva ROC, significando que se tiene una alta sensitividad y especificidad, siendo aun mayor esta última.

```{r}
coords(roc_obj,"best","threshold")
```

Obteniendo así el umbral óptimo.

## 2. LDA

```{r}
mod_lda<-lda(satisfaction~.-Gender , data=df_train)
mod_lda
```

```{r}
predicciones_lda<-predict(mod_lda, newdata=df_test)
confusionMatrix(table(df_test$satisfaction,predicciones_lda$class, dnn=c("Clase real", "Clase predicha")))
```

## 3. QDA

```{r}
mod_qda<-qda(satisfaction~.-Gender, data=df_train)
mod_qda
```

```{r}
predicciones_qda<-predict(mod_qda, newdata=df_test)
confusionMatrix(table(df_test$satisfaction,predicciones_qda$class, dnn=c("Clase real", "Clase predicha")))
```

## 4. KNN

```{r}
train_knn = df_train %>% dplyr::select(-c("satisfaction","Gender","Customer.Type","Class","Type.of.Travel"))
test_knn = df_test %>% dplyr::select(-c("satisfaction","Gender","Customer.Type","Class","Type.of.Travel"))
```

```{r}
### KNN iterativo ----
overall.accuracy = c()
for (i in 1:15){
set.seed(1)
knn_pred=knn(train_knn,test_knn,df_train$satisfaction,k=i)
values = confusionMatrix(table(knn_pred,df_test$satisfaction))
overall = values$overall
overall.accuracy = append(overall.accuracy , overall["Accuracy"])
}
acc = data.frame(k=1:15, accuracy = overall.accuracy)
ggplot(acc) + aes(x = k, y = accuracy) +geom_line(size = 0.5, colour = "#112446") +  theme_minimal() + geom_vline(xintercept = 11, color = "red")
```

Observando que se puede lograr una mayor precisión en el vecino 11.

```{r}
### Matriz de confusión ----

knn.pred=knn(train_knn,test_knn,df_train$satisfaction,k=11)
confusionMatrix(table(knn.pred,df_test$satisfaction))
```

## 5. Árbol de decisión

```{r}
tree.fit = rpart(formula=satisfaction~ .-Gender , data=df_train)
plot(tree.fit)
text(tree.fit, pretty=10)
```

```{r}

### Matriz de confusión ----

tree_pred=predict(tree.fit, df_test , type ="class")
confusionMatrix(table(tree_pred,df_test$satisfaction))
```

## 6. SVM

```{r}
df_train_svm<-df_train %>% dplyr:: select (-Gender,-Customer.Type,-Type.of.Travel,-Class)
df_test_svm<-df_test %>% dplyr:: select (-Gender,-Customer.Type,-Type.of.Travel,-Class)
```

```{r}
df_train_svm[-19]=scale(df_train_svm[-19])
df_test_svm[-19]=scale(df_test_svm[-19])
```

```{r}
svm_fit <- svm(formula = satisfaction ~ ., data = df_train_svm, kernel = 'linear')

summary(svm_fit)

#
```

```{r}

```

```{r}
#plot(svm_fit, df_train_svm)}

```

```{r}
confusionMatrix(table(true=df_test$satisfaction,pred=predict(svm_fit, newdata=df_test_svm)))
```

```{r}
svm_fit2 <- svm(formula = satisfaction ~ ., data = df_train_svm, kernel = 'radial')

summary(svm_fit2)

#plot(svm_fit2, df_train_svm)
```

```{r}
confusionMatrix(table(true=df_test$satisfaction,pred=predict(svm_fit2, newdata=df_test_svm)))
```

# Métodos no supervisados

## 7. Análisis de componentes principales

```{r}
variables_numericas_train<-df_train[,sapply(df_train,is.numeric)] #selecciona las columnas numericas
variables_numericas_test<-df_test[,sapply(df_test,is.numeric)]
```

```{r}
pca <- prcomp(variables_numericas_train, scale = TRUE)

```

```{r}
#Varianza explicada por componente ----
prop_varianza <- pca$sdev^2 / sum(pca$sdev^2)

pca_var<-ggplot(data = data.frame(prop_varianza, pc = 1:length(prop_varianza)), aes(x = pc, y = prop_varianza)) + 
  geom_col(width = 0.3) +  scale_y_continuous(limits = c(0,1)) +  theme_bw() +
  labs(x = "Componente principal", y = "Prop. de varianza explicada")
pca_var

#Varianza explicada acumulada ----
prop_varianza_acum <- cumsum(prop_varianza)

pca_var_acum<-ggplot(data = data.frame(prop_varianza_acum, pc = 1:length(prop_varianza)), aes(x = pc, y = prop_varianza_acum, group = 1)) +
  geom_point() +  geom_line() +  theme_bw() +  labs(x = "Componente principal", y = "Prop. varianza explicada acumulada")

pca_var_acum

biplot(pca)

```

```{r}
library(factoextra)

fviz_eig(pca)

fviz_pca_biplot(pca, repel = TRUE,
                col.var = "#D2691E", # color para las variables
                col.ind = "#000000"  # colores de las estaciones
)
```

### 

```{r}
library(corrplot)
var <- get_pca_var(pca)
corrplot(var$cos2, is.corr = FALSE)


plot_prcomp(variables_numericas_train)
```

```{r}

```

## 8. K-Means

```{r}
df_kmeans=scale(variables_numericas_train)
```

```{r}
k2 <- kmeans(df_kmeans, centers = 2, nstart = 25)
k3 <- kmeans(df_kmeans, centers = 3, nstart = 25)
k4 <- kmeans(df_kmeans, centers = 4, nstart = 25)
k5 <- kmeans(df_kmeans, centers = 5, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = df_kmeans) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df_kmeans) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df_kmeans) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df_kmeans) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)

```

```{r}
# Optimal K

fviz_nbclust(df_kmeans, kmeans, method = "silhouette", k.max = 10)

```

```{r}
fviz_nbclust(df_kmeans, kmeans, method = "wss", k.max = 10)
```

```{r}
fviz_nbclust(df_kmeans, kmeans, "gap_stat", k.max = 10)
```

```{r}
fviz_eig(prcomp(df_kmeans, scale = T))
```

## 9. Agrupamiento jerárquico

```{r}
## Method 1
# Dissimilarity matrix
d <- dist(df_kmeans, method = "euclidean")

# Hierarchical clustering using Complete Linkage
hc1 <- hclust(d, method = "complete" )

# Plot the obtained dendrogram
plot(hc1, cex = 0.6, hang = -1)
```

```{r}
# Prunning

# Ward's method
hc5 <- hclust(d, method = "ward.D2" )

# Cut tree into 4 groups
sub_grp <- cutree(hc5, k = 2)

# Number of members in each cluster
table(sub_grp)

#df_kmeans %>%
  #mutate(cluster = sub_grp) %>%
  #head

plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 2, border = 2:5)
```

```{r}
fviz_nbclust(df_kmeans, FUN = hcut, method = "wss")
```

```{r}

fviz_nbclust(df_kmeans, FUN = hcut, method = "silhouette")
```

```{r}
gap_stat <- clusGap(df_kmeans, FUN = hcut, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
```
